---
title: 'Time Estimate Processor V5'
description: 'This workflow processes time estimate data, likely from a task management system like ClickUp, triggered by webhooks. It identifies relevant tasks based on tags and team assignments, checks for existing time estimates, and queues tasks for processing. It also handles potential duplicates and updates queue numbers.'
api: "POST /trigger-estimate"
---

## Workflow Details

- **Workflow ID**: `97y1a4k8WyTqCDlB`
- **Name**: Time Estimate Processor V5
- **Server**: Not explicitly stated, but webhook URL suggests 'sisx.thesqd.com' and 'sis2.thesqd.com' are involved.
- **Status**: Active
- **Created**: November 26, 2024
- **Last Updated**: July 7, 2025
- **Tags**: Supabase

## Webhook Endpoint

```
POST https://sisx.thesqd.com/webhook/trigger-estimate
```

## Supabase Trigger Setup

The following SQL script should be pasted into your Supabase query editor to set up the trigger:

```sql
-- First, create the function to check conditions and send webhook
CREATE OR REPLACE FUNCTION time_estimate_processor_v2(task_id_input text) RETURNS void AS $$
DECLARE
    task_data json;
    webhook_url text := 'https://hkdk.events/cum8jgusyfp155';
BEGIN
    -- Get the task data that matches our conditions
    SELECT json_agg(task_results.*)
    INTO task_data
    FROM (
        SELECT DISTINCT
            t.task_id,
            t.name,
            cf.account,
            t.created_at,
            th.tag_after,
            t.row_created
        FROM tasks t
        JOIN tag_history th ON t.task_id = th.task_id
        JOIN clickup_tags ct ON th.tag_after = ct.name
        JOIN clickup_lists cl ON t.list_id = cl.id
        JOIN clickup_folders cf ON cl.folder = cf.id
        LEFT JOIN LATERAL (
            SELECT estimate_mins_after
            FROM time_estimate_history
            WHERE task_id = t.task_id
            ORDER BY created_at DESC
            LIMIT 1
        ) teh ON true
        WHERE t.task_id = task_id_input
        AND DATE(t.row_created) = CURRENT_DATE
        AND ct.status = 'Active'
        AND cl.space IN (1301552, 1306092)
        AND teh.estimate_mins_after IS NULL
    ) task_results;

    -- Only send webhook if there are results
    IF task_data IS NOT NULL AND task_data::text != '[]' THEN
        PERFORM http_post(
            webhook_url,
            task_data::text,
            'application/json'
        );
    END IF;
END;
$$ LANGUAGE plpgsql;

-- Create the notification trigger function
CREATE OR REPLACE FUNCTION time_estimate_processor_v2() RETURNS trigger AS $$
BEGIN
    -- Call the check and notify function
    PERFORM time_estimate_processor_v2(
        CASE
            WHEN TG_TABLE_NAME = 'tasks' THEN NEW.task_id
            WHEN TG_TABLE_NAME = 'tag_history' THEN NEW.task_id
        END
    );
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Create triggers for both tables

CREATE TRIGGER tag_history_time_estimate_processor_v2
    AFTER INSERT
    ON tag_history
    FOR EACH ROW
    EXECUTE FUNCTION time_estimate_processor_v2();

```

## Workflow Process

### 1. Sticky Note
- **Purpose**: This sticky note contains crucial SQL code for setting up a Supabase trigger. It defines a PostgreSQL function (`time_estimate_processor_v2`) that checks task conditions and sends a webhook, and a trigger function to call this processor when new data is inserted into `tag_history`.

### 2. Webhook Trigger
- **Path**: `/trigger-estimate`
- **Method**: POST
- **Purpose**: Receives incoming webhook requests to initiate the workflow. It's configured to expect JSON data in the body.

### 3. Edit Fields
- **Purpose**: Extracts and formats a unique identifier (`item_id`) from the incoming webhook data and request headers, likely for duplicate detection.
- **Parameters**:
  - **item_id**: `={{ $json.body[0].tag_after }}_{{ $json.body[0].task_id }}_attempt-{{ $json.headers[\"x-hookdeck-attempt-count\"] }}`

### 4. Remove Duplicates
- **Purpose**: Prevents duplicate processing of tasks by checking if a task's `item_id` has been seen in previous workflow executions.
- **Parameters**:
  - **dedupeValue**: `={{ $json.item_id }}`
  - **operation**: `removeItemsSeenInPreviousExecutions`

### 5. If1
- **Purpose**: Checks if there are any keys in the processed data, likely to determine if there's data to proceed with.
- **Parameters**:
  - **conditions**:
    - **combinator**: `and`
    - **conditions**:
      - **leftValue**: `={{ $json.keys() }}`
      - **operator**: `notEmpty`

### 6. Time Data Helper
- **Purpose**: Executes another n8n workflow (`TUL93CDbrOZP24aU` - "Time Estimate Processor Time Data Helper") for each item, likely to gather or process specific time-related data.
- **Parameters**:
  - **mode**: `each`
  - **waitForSubWorkflow**: `true`

### 7. Estimate Helper
- **Purpose**: Executes another n8n workflow (`lGjC2quFOtKA4fFP` - "Time Estimate Helper") for each item, likely to perform further processing or calculations related to time estimates.
- **Parameters**:
  - **mode**: `each`
  - **waitForSubWorkflow**: `true`

### 8. Execution Data2
- **Purpose**: Stores a 'duplicate' flag as `true` in the execution data. This node is likely reached when the `If1` condition is not met, indicating a potential duplicate or an empty data set.
- **Parameters**:
  - **dataToSave**:
    - **duplicate**: `true`

### 9. Filter
- **Purpose**: Filters the data based on several criteria related to responsible department, time estimate presence, and an auto-assign override.
- **Parameters**:
  - **conditions**:
    - **combinator**: `and`
    - **conditions**:
      - **leftValue**: `={{ $json.resp_dept == 'Design Squad' || $json.resp_dept == 'Video Squad' }}` (checks if `resp_dept` is 'Design Squad' or 'Video Squad')
      - **operator**: `true`
      - **leftValue**: `={{ $json.time_estimate }}` (checks if `time_estimate` exists)
      - **operator**: `exists`
      - **leftValue**: `={{ $json.unassigned }}` (checks if `unassigned` is true)
      - **operator**: `true`
      - **leftValue**: `={{ $json.auto_assign_override }}` (checks if `auto_assign_override` is not equal to true)
      - **operator**: `notEquals`

### 10. If
- **Purpose**: Checks if the `status` field is equal to 'triggered'. This likely determines the next step based on the outcome of the filtering.
- **Parameters**:
  - **conditions**:
    - **combinator**: `and`
    - **conditions**:
      - **leftValue**: `={{ $json.status }}`
      - **operator**: `equals`
      - **rightValue**: `triggered`

### 11. AA Trigger
- **Purpose**: Executes another n8n workflow (`UHdeJMNPJTdY6QA4` - "AA Trigger Helper v2") with retry logic, likely to trigger an automated assignment process.
- **Parameters**:
  - **options**:
    - **waitForSubWorkflow**: `true`
  - **retryOnFail**: `true`
  - **waitBetweenTries**: `5000`

### 12. Wait
- **Purpose**: Pauses the workflow execution for a specified duration. This is part of the retry mechanism for the "AA Trigger" sub-workflow.
- **Parameters**: (No specific parameters shown, likely default wait time)

### 13. Supabase
- **Purpose**: Queries the `aa_log` table in Supabase to find existing entries for the same account and task, but with a different status or where the current task is not yet queued. This helps in managing the queue.
- **Parameters**:
  - **operation**: `getAll`
  - **tableId**: `aa_log`
  - **filters**:
    - **conditions**:
      - **keyName**: `account`, **keyValue**: `={{ $json.account }}`, **condition**: `eq`
      - **keyName**: `status`, **keyValue**: `queued`, **condition**: `eq`
      - **keyName**: `task_id`, **keyValue**: `={{ $json.task_id }}`, **condition**: `neq`

### 14. Merge1
- **Purpose**: Merges the results from different branches of the workflow, likely to combine processed data before the next steps.
- **Parameters**:
  - **mode**: `chooseBranch`

### 15. Edit Fields2
- **Purpose**: Calculates and sets the `queue_num` based on the number of existing items found in the Supabase query plus one.
- **Parameters**:
  - **assignments**:
    - **queue_num**: `={{ $('Supabase').all().length + 1 }}`

### 16. AA Trigger - Queued
- **Purpose**: Executes the "AA Trigger Helper v2" workflow again, this time likely for tasks that have been identified as needing to be queued.
- **Parameters**:
  - **mode**: `each`
  - **waitForSubWorkflow**: `true`

### 17. Refresh Queue Numbers
- **Purpose**: Makes an HTTP POST request to a webhook endpoint (`https://sis2.thesqd.com/webhook/refresh-queues`) to update queue numbers. This is likely triggered when certain conditions are met after the Supabase query.
- **Parameters**:
  - **url**: `https://sis2.thesqd.com/webhook/refresh-queues`
  - **method**: `POST`
  - **sendBody**: `true`
  - **bodyParameters**:
    - **parameters**:
      - **name**: `account`, **value**: `={{ $json.account }}`

### 18. Wait1
- **Purpose**: Pauses workflow execution after attempting to refresh queue numbers.
- **Parameters**: (No specific parameters shown)

## Data Flow

Webhook Trigger → Edit Fields → Remove Duplicates → If1 → (Time Data Helper | Estimate Helper) → (Filter → If → AA Trigger → Wait) | (Execution Data2) → Supabase → Merge1 → Edit Fields2 → AA Trigger - Queued → Refresh Queue Numbers → Wait1

## Error Handling

- **Error Workflow**: `p96PdgC9o16nuAdv`
- **Execution Order**: `v1`
- **Execution Timeout**: 58 seconds

## Authentication

- **Supabase**: Uses a credential with ID `NifWy1sih0M2biEc` named "Squad Data".

## Usage Examples

### Webhook Payload Example
When a new task is updated with a relevant tag, a webhook might send a payload like this:

```json
{
  "body": [
    {
      "name": "Sunday Sermon Recap - Social Media Graphics",
      "account": 3583,
      "task_id": "86dx6nmyf",
      "tag_after": "social1-3",
      "created_at": "2025-07-07",
      "row_created": "2025-07-07T17:12:54.280022+00:00"
    }
  ],
  "query": {},
  "params": {},
  "headers": {
    "x-hookdeck-attempt-count": "3",
    "x-hookdeck-source-name": "Supabase",
    "x-hookdeck-connection-name": "time-estimate-processor"
  }
}
```
```